{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MedReminderDataset(Dataset):\n",
    "    def __init__(self, images_dir, labels_dir, image_list, transform=None):\n",
    "        \"\"\"\n",
    "        :param images_dir: Directory containing images\n",
    "        :param labels_dir: Directory containing labels as individual JSON files\n",
    "        :param image_list: List of image file names\n",
    "        :param transform: Transformations to apply to images\n",
    "        \"\"\"\n",
    "        self.images_dir = images_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.image_list = image_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_list[idx]\n",
    "        image_path = os.path.join(self.images_dir, image_name)\n",
    "        label_path = os.path.join(self.labels_dir, image_name.replace('.png', '.json'))  # Adjust if using different extension\n",
    "\n",
    "        # Load the image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Load and process the label\n",
    "        with open(label_path, 'r') as f:\n",
    "            label_data = json.load(f)\n",
    "\n",
    "        # Extract medicines and syrups details\n",
    "        medicines = label_data.get('medicines', [])\n",
    "        syrups = label_data.get('syrups', [])\n",
    "\n",
    "        # Format the data into structured lists\n",
    "        medicines_details = []\n",
    "        for medicine in medicines:\n",
    "            medicines_details.append([\n",
    "                medicine.get('name', ''), \n",
    "                medicine.get('dosage', ''), \n",
    "                medicine.get('frequency', ''), \n",
    "                medicine.get('duration', '')\n",
    "            ])\n",
    "        \n",
    "        syrups_details = []\n",
    "        for syrup in syrups:\n",
    "            syrups_details.append([\n",
    "                syrup.get('name', ''), \n",
    "                syrup.get('dosage', ''), \n",
    "                syrup.get('frequency', ''), \n",
    "                syrup.get('duration', '')\n",
    "            ])\n",
    "\n",
    "        # Flatten the labels to include all details in one list\n",
    "        labels = medicines_details + syrups_details\n",
    "\n",
    "        return image, labels  # Return image and label details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class MedReminderModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MedReminderModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 32 * 32, 128)  # Adjust dimensions for your dataset\n",
    "        self.fc2 = nn.Linear(128, 4 * 5)  # Output 4 values (name, dosage, frequency, duration) for 5 items (medicines + syrups)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 32 * 32)  # Flatten the output of the convolution layers\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # This is a structured output, with 4 fields for each of 5 items (adjust accordingly)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\Harsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6491190345259383\n",
      "Epoch 2/10, Loss: 0.014066506730368957\n",
      "Epoch 3/10, Loss: 0.005520643767459651\n",
      "Epoch 4/10, Loss: 0.005660615199588482\n",
      "Epoch 5/10, Loss: 0.004437341293197414\n",
      "Epoch 6/10, Loss: 0.004495116488569489\n",
      "Epoch 7/10, Loss: 0.0049080270490814235\n",
      "Epoch 8/10, Loss: 0.004186028612466747\n",
      "Epoch 9/10, Loss: 0.004239854559950262\n",
      "Epoch 10/10, Loss: 0.004603866140244757\n",
      "Model saved as med_reminder.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import json\n",
    "import re\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Dataset class\n",
    "class MedReminderDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.image_files = os.listdir(image_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_file = self.image_files[idx]\n",
    "        image_path = os.path.join(self.image_dir, image_file)\n",
    "        label_path = os.path.join(self.label_dir, os.path.splitext(image_file)[0] + \".json\")\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Load or extract labels\n",
    "        with open(label_path, \"r\") as f:\n",
    "            labels = json.load(f)\n",
    "\n",
    "        return image, labels\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_prescription_details(image_path):\n",
    "        \"\"\"\n",
    "        Extract text from the image using OCR (pytesseract).\n",
    "        \"\"\"\n",
    "        text = pytesseract.image_to_string(Image.open(image_path))\n",
    "        return text\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_prescription_details(extracted_text):\n",
    "        \"\"\"\n",
    "        Parse extracted text to identify medicines and syrups with their details.\n",
    "        Uses regex for improved accuracy.\n",
    "        \"\"\"\n",
    "        medicines = []\n",
    "        syrups = []\n",
    "        \n",
    "        # Define regex patterns\n",
    "        dosage_pattern = r\"(\\d+(\\.\\d+)?\\s?(MG|Mg|mg|G|g|Ml|ML|ml|MCG|Mcg|mcg|Unit|UNIT|unit))\"\n",
    "        frequency_pattern = r\"(\\d+\\s*(x|times)?\\s*(per\\s*day|daily|once|twice|\\d+\\s*times))\"\n",
    "        duration_pattern = r\"(\\d+\\s*(days?|weeks?|months?))\"\n",
    "        \n",
    "        # Medicine and syrup keywords (using regex)\n",
    "        medicine_keywords = r\"(tablet|tab|cap|capsule|pill|medicine|TAB|Tab|TABLET|Tablet|CAP|CAPSULE|Capsule|PILL|Pill|MEDICINE|Medicine)\"\n",
    "        syrup_keywords = r\"(syrup|Syrup|SYRUP|SYP|Syp|syp|liquid|LIQUID|Liquid|liq|Liq)\"\n",
    "        \n",
    "        lines = extracted_text.split(\"\\n\")\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "\n",
    "            # Skip lines with irrelevant information\n",
    "            if any(irrelevant in line.lower() for irrelevant in [\"dr.\", \"address\", \"phone\", \"signature\"]):\n",
    "                continue\n",
    "\n",
    "            # Check for medicines using regex\n",
    "            if re.search(medicine_keywords, line.lower()):\n",
    "                medicine = MedReminderDataset.parse_line(line, dosage_pattern, frequency_pattern, duration_pattern, \"medicine\")\n",
    "                if medicine:\n",
    "                    medicines.append(medicine)\n",
    "            \n",
    "            # Check for syrups using regex\n",
    "            elif re.search(syrup_keywords, line.lower()):\n",
    "                syrup = MedReminderDataset.parse_line(line, dosage_pattern, frequency_pattern, duration_pattern, \"syrup\")\n",
    "                if syrup:\n",
    "                    syrups.append(syrup)\n",
    "\n",
    "        return medicines, syrups\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_line(line, dosage_pattern, frequency_pattern, duration_pattern, type_of_med):\n",
    "        \"\"\"\n",
    "        Parse a single line to extract details like name, dosage, frequency, and duration using regex.\n",
    "        Type of medicine or syrup is passed as an argument ('medicine' or 'syrup').\n",
    "        \"\"\"\n",
    "        details = {\"name\": \"\", \"dosage\": \"\", \"frequency\": \"\", \"duration\": \"\", \"type\": type_of_med}\n",
    "        \n",
    "        # Extract the name (first word in the line as name assumption)\n",
    "        tokens = line.split()\n",
    "        if len(tokens) > 0:\n",
    "            details[\"name\"] = tokens[0]  # First token is typically the name\n",
    "\n",
    "        # Use regex to extract dosage, frequency, and duration\n",
    "        dosage_match = re.search(dosage_pattern, line)\n",
    "        if dosage_match:\n",
    "            details[\"dosage\"] = dosage_match.group(0)\n",
    "\n",
    "        frequency_match = re.search(frequency_pattern, line)\n",
    "        if frequency_match:\n",
    "            details[\"frequency\"] = frequency_match.group(0)\n",
    "\n",
    "        duration_match = re.search(duration_pattern, line)\n",
    "        if duration_match:\n",
    "            details[\"duration\"] = duration_match.group(0)\n",
    "\n",
    "        # If the line contains relevant information, return the details\n",
    "        if any(details[key] != \"\" for key in details):\n",
    "            return details\n",
    "        return None\n",
    "\n",
    "# Custom collate function for DataLoader\n",
    "def custom_collate_fn(batch):\n",
    "    images = torch.stack([item[0] for item in batch])  # Stack all images\n",
    "    labels = [item[1] for item in batch]  # Keep labels as-is (list of dictionaries)\n",
    "    return images, labels\n",
    "\n",
    "# Model definition\n",
    "class MedReminderModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MedReminderModel, self).__init__()\n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        self.base_model.fc = nn.Linear(self.base_model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "# Loss calculation (customized for dictionary labels)\n",
    "def calculate_loss(outputs, labels, criterion):\n",
    "    total_loss = 0.0\n",
    "    for i, label_dict in enumerate(labels):\n",
    "        medicines = label_dict.get(\"medicines\", [])\n",
    "        syrups = label_dict.get(\"syrups\", [])\n",
    "        loss = criterion(outputs[i], torch.tensor(len(medicines) + len(syrups), dtype=torch.float32))\n",
    "        total_loss += loss\n",
    "    return total_loss / len(labels)\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    image_dir = \"dataset/images\"\n",
    "    label_dir = \"dataset/labels\"\n",
    "    batch_size = 16\n",
    "    num_epochs = 10\n",
    "    learning_rate = 0.001\n",
    "    num_classes = 10  # Adjust based on your classification categories\n",
    "\n",
    "    # Data transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # Dataset and DataLoader\n",
    "    dataset = MedReminderDataset(image_dir, label_dir, transform=transform)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "    # Model, criterion, and optimizer\n",
    "    model = MedReminderModel(num_classes=num_classes)\n",
    "    criterion = nn.MSELoss()  # Example criterion; adapt for your specific use case\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = calculate_loss(outputs, labels, criterion)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), \"med_reminder.pth\")\n",
    "    print(\"Model saved as med_reminder.pth\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
